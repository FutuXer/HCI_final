from PyQt5.QtCore import QThread, pyqtSignal
import time
from aip import AipSpeech
import pyaudio
import wave
import os

class VoiceInputThread(QThread):
    result_ready = pyqtSignal(str)  # ä¿®æ”¹ä¿¡å·åç§°ä¸ui.pyåŒ¹é…
    status_update = pyqtSignal(str)
    error_occurred = pyqtSignal(str)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.running = True

        # ç™¾åº¦è¯­éŸ³APIé…ç½®
        self.APP_ID = '6927050'
        self.API_KEY = 'vtXVCLNnGAU348EVajXm5PZF'
        self.SECRET_KEY = 'lG439CVdi9Kd4VDfCa52yjTMvbjtJdAy'
        self.client = AipSpeech(self.APP_ID, self.API_KEY, self.SECRET_KEY)

        # éŸ³é¢‘å‚æ•°
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.CHUNK = 1024
        self.MAX_RECORD_SECONDS = 10
        self.WAVE_OUTPUT_FILENAME = "temp_audio.wav"

    def record_audio(self):
        """å½•åˆ¶éŸ³é¢‘å¹¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶"""
        audio = pyaudio.PyAudio()

        stream = audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK
        )

        self.status_update.emit("ğŸ¤ æ­£åœ¨å½•éŸ³...è¯·è¯´è¯")
        frames = []

        for _ in range(0, int(self.RATE / self.CHUNK * self.MAX_RECORD_SECONDS)):
            if not self.running:
                break
            data = stream.read(self.CHUNK)
            frames.append(data)

        stream.stop_stream()
        stream.close()
        audio.terminate()

        # ä¿å­˜ä¸ºWAVæ–‡ä»¶ï¼ˆç™¾åº¦APIè¦æ±‚ï¼‰
        with wave.open(self.WAVE_OUTPUT_FILENAME, 'wb') as wf:
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(audio.get_sample_size(self.FORMAT))
            wf.setframerate(self.RATE)
            wf.writeframes(b''.join(frames))

        return self.WAVE_OUTPUT_FILENAME

    def recognize_audio(self, audio_file):
        """ä½¿ç”¨ç™¾åº¦APIè¯†åˆ«éŸ³é¢‘"""
        with open(audio_file, 'rb') as f:
            audio_data = f.read()

        # è¯†åˆ«æ™®é€šè¯ï¼ˆ1537ä¸ºæ™®é€šè¯æ¨¡å‹ï¼‰
        result = self.client.asr(audio_data, 'wav', self.RATE, {
            'dev_pid': 1537
        })

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(audio_file):
            os.remove(audio_file)

        if result.get('err_no') != 0:
            raise Exception(f"ç™¾åº¦APIé”™è¯¯: {result.get('err_msg')}")

        return result.get('result')[0]

    def run(self):
        try:
            while self.running:
                self.status_update.emit("æ­£åœ¨å‡†å¤‡å½•éŸ³è®¾å¤‡...")
                audio_file = self.record_audio()

                if not self.running:
                    break

                self.status_update.emit("ğŸ” æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
                start_time = time.time()

                text = self.recognize_audio(audio_file)
                processing_time = round(time.time() - start_time, 2)

                self.status_update.emit(f"âœ… è¯†åˆ«å®Œæˆ (è€—æ—¶ {processing_time}s)")
                self.result_ready.emit(text)  # ç›´æ¥å‘å°„æ–‡æœ¬ï¼Œä¸å¸¦æ—¶é—´æˆ³

        except Exception as e:
            self.error_occurred.emit(f"âš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            if os.path.exists(self.WAVE_OUTPUT_FILENAME):
                os.remove(self.WAVE_OUTPUT_FILENAME)

    def stop(self):
        self.running = False
        self.status_update.emit("ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²åœæ­¢")

