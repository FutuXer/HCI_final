from PyQt5.QtCore import QThread, pyqtSignal, QMutex
import time
from aip import AipSpeech
import pyaudio
import wave
import os
import speech_recognition as sr


class VoiceInputThread(QThread):
    result_ready = pyqtSignal(str)
    status_update = pyqtSignal(str)
    error_occurred = pyqtSignal(str)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.mutex = QMutex()  # æ­£ç¡®åˆå§‹åŒ–äº’æ–¥é”
        self._running = False  # ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªè¿è¡Œæ ‡å¿—

        # åˆå§‹åŒ–è¯†åˆ«å™¨
        self.recognizer = sr.Recognizer()
        self.recognizer.pause_threshold = 0.8  # è®¾ç½®é™éŸ³æ£€æµ‹é˜ˆå€¼

        # ç™¾åº¦è¯­éŸ³APIé…ç½®
        self.APP_ID = '6927050'
        self.API_KEY = 'vtXVCLNnGAU348EVajXm5PZF'
        self.SECRET_KEY = 'lG439CVdi9Kd4VDfCa52yjTMvbjtJdAy'
        self.client = AipSpeech(self.APP_ID, self.API_KEY, self.SECRET_KEY)

        # éŸ³é¢‘å‚æ•°
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.CHUNK = 1024
        self.WAVE_OUTPUT_FILENAME = "temp_audio.wav"

    def recognize_audio(self, audio_file):
        if audio_file is None:
            raise Exception("æ— æœ‰æ•ˆéŸ³é¢‘è¾“å…¥")
        """ä½¿ç”¨ç™¾åº¦è¯­éŸ³APIè¯†åˆ«éŸ³é¢‘æ–‡ä»¶"""
        try:
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            with open(audio_file, 'rb') as audio_data:
                audio_content = audio_data.read()

            # è°ƒç”¨ç™¾åº¦è¯­éŸ³è¯†åˆ«APIï¼ˆä¿®æ­£å‚æ•°æ ¼å¼ï¼‰
            result = self.client.asr(
                audio_content,
                'wav',
                16000, {
                    'dev_pid': 1537  # 1537è¡¨ç¤ºæ™®é€šè¯(çº¯ä¸­æ–‡è¯†åˆ«)
                }
            )

            # æ£€æŸ¥è¯†åˆ«ç»“æžœ
            if result.get('err_no') != 0:
                error_msg = result.get('err_msg', 'æœªçŸ¥é”™è¯¯')
                # ç‰¹æ®Šå¤„ç†é™éŸ³è¶…æ—¶é”™è¯¯(é”™è¯¯ç 2001)
                if result['err_no'] == 2001:
                    raise sr.UnknownValueError("æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥")
                raise Exception(f"ç™¾åº¦APIé”™è¯¯: {error_msg}")

            # è¿”å›žè¯†åˆ«ç»“æžœ
            if 'result' in result and len(result['result']) > 0:
                return result['result'][0]
            else:
                raise Exception("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")

        except sr.UnknownValueError:
            raise Exception("æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹")
        except sr.RequestError as e:
            raise Exception(f"è¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {str(e)}")
        except Exception as e:
            raise Exception(f"è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

    def stop(self):
        self.mutex.lock()
        self._running = False
        self.mutex.unlock()
        self.status_update.emit("ðŸ›‘ å·²åœæ­¢")
        self.wait()  # é˜»å¡žç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œç¡®ä¿çº¿ç¨‹å®Œå…¨é€€å‡ºåŽå†è¿”å›ž

    def run(self):
        self.mutex.lock()
        self._running = True
        self.mutex.unlock()

        try:
            from ui.resources import AudioManager
            audio = AudioManager()

            self.status_update.emit("ðŸŽ¤ æ­£åœ¨å½•éŸ³...è¯·è¯´è¯")

            stream = audio.p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                frames_per_buffer=self.CHUNK
            )

            frames = []

            while True:
                self.mutex.lock()
                running = self._running
                self.mutex.unlock()

                if not running:
                    break

                data = stream.read(self.CHUNK)
                frames.append(data)

                # è¿™é‡Œå¯ä»¥åŠ ä¸ªé™åˆ¶æœ€é•¿å½•éŸ³æ—¶é—´ï¼Œä¾‹å¦‚10ç§’ï¼Œé˜²æ­¢æ­»å¾ªçŽ¯
                if len(frames) >= int(self.RATE / self.CHUNK * 10):
                    break

            stream.stop_stream()
            stream.close()

            if frames:
                with wave.open(self.WAVE_OUTPUT_FILENAME, 'wb') as wf:
                    wf.setnchannels(self.CHANNELS)
                    wf.setsampwidth(audio.p.get_sample_size(self.FORMAT))
                    wf.setframerate(self.RATE)
                    wf.writeframes(b''.join(frames))

                self.status_update.emit("è¯†åˆ«ä¸­...")
                text = self.recognize_audio(self.WAVE_OUTPUT_FILENAME)
                self.result_ready.emit(text)

        except Exception as e:
            self.error_occurred.emit(f"è¯†åˆ«é”™è¯¯: {str(e)}")
        finally:
            self.status_update.emit("å‡†å¤‡å°±ç»ª")
            if os.path.exists(self.WAVE_OUTPUT_FILENAME):
                os.remove(self.WAVE_OUTPUT_FILENAME)
