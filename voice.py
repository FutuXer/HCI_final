from PyQt5.QtCore import QThread, pyqtSignal, QTimer
import time
from aip import AipSpeech
import pyaudio
import wave
import os
import speech_recognition as sr  # è¡¥å……ç¼ºå¤±çš„import


class VoiceInputThread(QThread):
    result_ready = pyqtSignal(str)
    status_update = pyqtSignal(str)
    error_occurred = pyqtSignal(str)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.running = True
        self.recognizer = sr.Recognizer()  # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

        # ç™¾åº¦è¯­éŸ³APIé…ç½®
        self.APP_ID = '6927050'
        self.API_KEY = 'vtXVCLNnGAU348EVajXm5PZF'
        self.SECRET_KEY = 'lG439CVdi9Kd4VDfCa52yjTMvbjtJdAy'
        self.client = AipSpeech(self.APP_ID, self.API_KEY, self.SECRET_KEY)

        # éŸ³é¢‘å‚æ•°ï¼ˆä¿æŒ5ç§’æˆªæ–­ï¼‰
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.CHUNK = 1024
        self.MAX_RECORD_SECONDS = 5  # ä¿æŒ5ç§’å½•éŸ³
        self.WAVE_OUTPUT_FILENAME = "temp_audio.wav"

    def stop(self):
        self.running = False
        if not self.wait(3000):  # 3ç§’è‡ªåŠ¨é€€å‡º
            self.terminate()
        self.status_update.emit("ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²åœæ­¢")

    def record_audio(self):
        """ä¿æŒåŸæœ‰5ç§’å½•éŸ³é€»è¾‘"""
        audio = pyaudio.PyAudio()
        stream = audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK
        )

        self.status_update.emit("ğŸ¤ æ­£åœ¨å½•éŸ³...è¯·è¯´è¯")
        frames = []

        for _ in range(0, int(self.RATE / self.CHUNK * self.MAX_RECORD_SECONDS)):
            if not self.running:
                break
            data = stream.read(self.CHUNK)
            frames.append(data)

        stream.stop_stream()
        stream.close()
        audio.terminate()

        with wave.open(self.WAVE_OUTPUT_FILENAME, 'wb') as wf:
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(audio.get_sample_size(self.FORMAT))
            wf.setframerate(self.RATE)
            wf.writeframes(b''.join(frames))

        return self.WAVE_OUTPUT_FILENAME

    def recognize_audio(self, audio_file):
        """å¸¦è¶…æ—¶æ§åˆ¶çš„è¯†åˆ«"""
        with open(audio_file, 'rb') as f:
            audio_data = f.read()

        # ç™¾åº¦APIçš„5ç§’è¶…æ—¶ä¿æŒä¸å˜
        result = self.client.asr(audio_data, 'wav', self.RATE, {
            'dev_pid': 1537
        })

        if os.path.exists(audio_file):
            os.remove(audio_file)

        if result.get('err_no') != 0:
            # ç‰¹æ®Šå¤„ç†é™é»˜è¶…æ—¶é”™è¯¯ï¼ˆé”™è¯¯ç 2001ï¼‰
            if result['err_no'] == 2001:
                raise sr.UnknownValueError("æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥")
            raise Exception(f"ç™¾åº¦APIé”™è¯¯: {result.get('err_msg')}")

        return result.get('result')[0]

    def run(self):
        try:
            while self.running:
                try:
                    self.status_update.emit("æ­£åœ¨å‡†å¤‡å½•éŸ³è®¾å¤‡...")
                    audio_file = self.record_audio()

                    if not self.running:
                        break

                    self.status_update.emit("ğŸ” æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
                    start_time = time.time()

                    text = self.recognize_audio(audio_file)
                    processing_time = round(time.time() - start_time, 2)

                    self.status_update.emit(f"âœ… è¯†åˆ«å®Œæˆ (è€—æ—¶ {processing_time}s)")
                    self.result_ready.emit(text)

                except sr.UnknownValueError:
                    if self.running:
                        self.error_occurred.emit("âŒ æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥")
                    continue
                except Exception as e:
                    if self.running:
                        self.error_occurred.emit(f"âš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue

        finally:
            if os.path.exists(self.WAVE_OUTPUT_FILENAME):
                os.remove(self.WAVE_OUTPUT_FILENAME)
